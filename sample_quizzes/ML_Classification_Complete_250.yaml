# Machine Learning Classification - Complete 250 Question Bank
# Comprehensive assessment covering all ML classification topics
# Part A: 125 Concept Questions | Part B: 125 Coding Questions

- id: 1
  question: What is the range of valid probability values?
  type: mc
  options:
  - A) Between -1 and 1
  - B) Between 0 and 1
  - C) Between 0 and 100
  - D) Any positive number
  correct: B
  explanation: Probabilities must be between 0 (impossible) and 1 (certain).
  chapter: Chapter 1.1
- id: 2
  question: If P(event A) = 0.30, what is P(not A)?
  type: mc
  options:
  - A) 0.30
  - B) 0.50
  - C) 0.70
  - D) 0.90
  correct: C
  explanation: 'Complement rule: P(not A) = 1 - P(A) = 0.70.'
  chapter: Chapter 1.1
- id: 3
  question: What does it mean if two events are mutually exclusive?
  type: mc
  options:
  - A) They always occur together
  - B) They cannot occur at the same time
  - C) They are independent events
  - D) They have equal probability
  correct: B
  explanation: Mutually exclusive events cannot happen simultaneously, like heads
    and tails.
  chapter: Chapter 1.1
- id: 4
  question: What is conditional probability P(A|B)?
  type: mc
  options:
  - A) Probability of A multiplied by B
  - B) Probability of A given that B has occurred
  - C) Probability of A plus B
  - D) Probability of A divided by 2
  correct: B
  explanation: Conditional probability measures the probability of A occurring given
    B occurred.
  chapter: Chapter 1.2
- id: 5
  question: In classification, what does P(Y=1 | X=x) represent?
  type: mc
  options:
  - A) The feature value x
  - B) The probability of class 1 given features x
  - C) The total number of samples
  - D) The classification error
  correct: B
  explanation: It represents the probability of positive class given specific feature
    values.
  chapter: Chapter 1.2
- id: 6
  question: Define "odds" in terms of probability.
  type: mc
  options:
  - A) 1 - P
  - B) P / (1 - P)
  - C) P * (1 - P)
  - D) log(P)
  correct: B
  explanation: Odds are calculated as probability of success divided by probability
    of failure.
  chapter: Chapter 1.3
- id: 7
  question: If P = 0.80, what are the odds?
  type: mc
  options:
  - A) 0.20
  - B) 0.80
  - C) 4.0
  - D) 1.25
  correct: C
  explanation: Odds = 0.80 / (1 - 0.80) = 0.80 / 0.20 = 4.0.
  chapter: Chapter 1.3
- id: 8
  question: What is the range of possible odds values?
  type: mc
  options:
  - A) Between 0 and 1
  - B) Between -∞ and +∞
  - C) Between 0 and +∞
  - D) Between 0 and 100
  correct: C
  explanation: Odds range from 0 to infinity; zero means impossible, infinity means
    certain.
  chapter: Chapter 1.3
- id: 9
  question: What is the logit (log-odds) when P = 0.5?
  type: mc
  options:
  - A) -1
  - B) 0
  - C) 0.5
  - D) 1
  correct: B
  explanation: When P = 0.5, odds = 1, and log(1) = 0.
  chapter: Chapter 1.3
- id: 10
  question: Why do we use log-odds instead of probability in logistic regression?
  type: mc
  options:
  - A) Log-odds are easier to calculate
  - B) Log-odds allow for a linear relationship with predictors
  - C) Log-odds are always positive
  - D) Probabilities cannot be modeled
  correct: B
  explanation: Log-odds can be any real number, allowing linear modeling with predictors.
  chapter: Chapter 1.3
- id: 11
  question: What is the output range of the sigmoid function?
  type: mc
  options:
  - A) (-∞, +∞)
  - B) (0, 1)
  - C) [0, 1]
  - D) (-1, 1)
  correct: B
  explanation: Sigmoid squashes any input into the probability range between 0 and
    1.
  chapter: Chapter 1.4
- id: 12
  question: What is σ(0) where σ is the sigmoid function?
  type: mc
  options:
  - A) 0
  - B) 0.5
  - C) 1
  - D) undefined
  correct: B
  explanation: Sigmoid of zero equals 0.5, representing equal probability for both
    classes.
  chapter: Chapter 1.4
- id: 13
  question: Describe the shape of the sigmoid curve.
  type: mc
  options:
  - A) Linear increasing
  - B) U-shaped
  - C) S-shaped
  - D) Bell-shaped
  correct: C
  explanation: 'Sigmoid has S-shape: flat at extremes, steep in middle around zero.'
  chapter: Chapter 1.4
- id: 14
  question: What is the relationship between sigmoid and logit?
  type: mc
  options:
  - A) They are the same function
  - B) Sigmoid is the inverse of logit
  - C) Logit is the derivative of sigmoid
  - D) They are unrelated
  correct: B
  explanation: Sigmoid converts log-odds to probability; logit does the inverse transformation.
  chapter: Chapter 1.4
- id: 15
  question: Why is the sigmoid function S-shaped rather than linear?
  type: mc
  options:
  - A) To make calculations easier
  - B) To constrain output to probability range (0,1)
  - C) To increase model complexity
  - D) It's purely aesthetic
  correct: B
  explanation: S-shape ensures output stays within valid probability range of 0 to
    1.
  chapter: Chapter 1.4
- id: 16
  question: What distinguishes classification from regression?
  type: mc
  options:
  - A) Number of features used
  - B) Classification predicts categorical outcomes, regression predicts continuous
  - C) Classification is always more accurate
  - D) Regression cannot use multiple features
  correct: B
  explanation: Classification predicts discrete categories; regression predicts continuous
    numerical values.
  chapter: Chapter 3
- id: 17
  question: Define binary classification.
  type: mc
  options:
  - A) Classification with two features
  - B) Classification with exactly two possible class labels
  - C) Classification using binary code
  - D) Classification of 0s and 1s only
  correct: B
  explanation: Binary classification has exactly two possible outcomes, like yes/no
    or positive/negative.
  chapter: Chapter 3
- id: 18
  question: What is a class label?
  type: mc
  options:
  - A) The feature importance score
  - B) The categorical outcome we want to predict
  - C) The model accuracy
  - D) The number of classes
  correct: B
  explanation: Class label is the categorical outcome variable we're trying to predict.
  chapter: Chapter 3
- id: 19
  question: What is class imbalance?
  type: mc
  options:
  - A) When features have different scales
  - B) When one class has significantly more samples than another
  - C) When the model is biased
  - D) When classes overlap
  correct: B
  explanation: Class imbalance means one class has significantly more samples than
    the other.
  chapter: Chapter 3
- id: 20
  question: Why is the naive classifier (always predicting majority class) problematic?
  type: mc
  options:
  - A) It's computationally expensive
  - B) It fails to identify minority class instances
  - C) It requires too much data
  - D) It cannot be implemented
  correct: B
  explanation: It ignores minority class completely, achieving high accuracy but poor
    real performance.
  chapter: Chapter 3
- id: 21
  question: Why does linear regression fail for binary outcomes?
  type: mc
  options:
  - A) It's too slow
  - B) It can predict values outside [0,1] range
  - C) It requires categorical inputs
  - D) It cannot handle two classes
  correct: B
  explanation: Linear regression can output values outside the valid probability range
    of 0-1.
  chapter: Chapter 4
- id: 22
  question: What function does logistic regression model as linear?
  type: mc
  options:
  - A) The probability directly
  - B) The log-odds (logit)
  - C) The error term
  - D) The class labels
  correct: B
  explanation: Logistic regression models log-odds as a linear combination of predictors.
  chapter: Chapter 4
- id: 23
  question: Write the logistic regression equation in terms of log-odds.
  type: mc
  options:
  - A) P(Y=1) = β₀ + β₁X
  - B) log(P) = β₀ + β₁X
  - C) log(P/(1-P)) = β₀ + β₁X
  - D) P/(1-P) = β₀ + β₁X
  correct: C
  explanation: 'This is the logit form: log(odds) = log(P/(1-P)) = β₀ + β₁X.'
  chapter: Chapter 4
- id: 24
  question: What does the coefficient β₁ represent in logistic regression?
  type: mc
  options:
  - A) The probability of class 1
  - B) The change in log-odds per unit change in X
  - C) The model accuracy
  - D) The intercept value
  correct: B
  explanation: β₁ represents change in log-odds for each one-unit increase in X.
  chapter: Chapter 4
- id: 25
  question: How is maximum likelihood estimation used in logistic regression?
  type: mc
  options:
  - A) To split the data
  - B) To find coefficients that maximize probability of observed data
  - C) To calculate accuracy
  - D) To normalize features
  correct: B
  explanation: MLE finds coefficients that maximize the likelihood of observing the
    training data.
  chapter: Chapter 4
- id: 26
  question: What does a positive coefficient mean in logistic regression?
  type: mc
  options:
  - A) The feature is irrelevant
  - B) Increasing the feature increases log-odds of class 1
  - C) The model is overfitting
  - D) The feature should be removed
  correct: B
  explanation: Positive coefficient means higher feature values increase probability
    of positive class.
  chapter: Chapter 5
- id: 27
  question: Define odds ratio.
  type: mc
  options:
  - A) The ratio of two probabilities
  - B) The ratio of odds for different feature values
  - C) The ratio of true to false predictions
  - D) The ratio of training to test accuracy
  correct: B
  explanation: Odds ratio compares odds at two different feature values.
  chapter: Chapter 5
- id: 28
  question: How do you calculate odds ratio from a coefficient?
  type: mc
  options:
  - A) β₁
  - B) log(β₁)
  - C) exp(β₁)
  - D) β₁²
  correct: C
  explanation: Exponentiating the coefficient gives the multiplicative change in odds.
  chapter: Chapter 5
- id: 29
  question: What does an odds ratio of 2.5 mean?
  type: mc
  options:
  - A) 25% probability increase
  - B) The odds are 2.5 times higher for 1 unit increase in feature
  - C) The accuracy is 2.5 times better
  - D) There are 2.5 classes
  correct: B
  explanation: One unit increase in feature multiplies the odds by 2.5.
  chapter: Chapter 5
- id: 30
  question: Why are standardized coefficients useful for interpretation?
  type: mc
  options:
  - A) They make the model faster
  - B) They allow comparison of relative feature importance
  - C) They improve accuracy
  - D) They are required for logistic regression
  correct: B
  explanation: Standardization allows fair comparison of effect sizes across different
    feature scales.
  chapter: Chapter 5
- id: 31
  question: What is a confusion matrix?
  type: mc
  options:
  - A) A matrix of model parameters
  - B) A table showing actual vs predicted classifications
  - C) A correlation matrix
  - D) A matrix of feature importances
  correct: B
  explanation: Confusion matrix shows counts of actual vs predicted classes in a table.
  chapter: Chapter 6
- id: 32
  question: Define True Positive (TP).
  type: mc
  options:
  - A) Correctly predicted negative cases
  - B) Correctly predicted positive cases
  - C) Incorrectly predicted positive cases
  - D) Incorrectly predicted negative cases
  correct: B
  explanation: 'True Positive: model correctly predicted the positive class.'
  chapter: Chapter 6
- id: 33
  question: Define False Positive (FP).
  type: mc
  options:
  - A) Actual positive predicted as negative
  - B) Actual negative predicted as positive
  - C) Actual positive predicted as positive
  - D) Actual negative predicted as negative
  correct: B
  explanation: 'False Positive: model incorrectly predicted positive when actually
    negative (Type I error).'
  chapter: Chapter 6
- id: 34
  question: What is accuracy and why can it be misleading?
  type: mc
  options:
  - A) Accuracy is always the best metric
  - B) Accuracy can be high even with poor minority class performance
  - C) Accuracy measures only false positives
  - D) Accuracy cannot be calculated for binary classification
  correct: B
  explanation: Accuracy can be misleading with imbalanced data; high from majority
    class only.
  chapter: Chapter 6
- id: 35
  question: Define precision (positive predictive value).
  type: mc
  options:
  - A) TP / (TP + FN)
  - B) TP / (TP + FP)
  - C) TN / (TN + FP)
  - D) (TP + TN) / Total
  correct: B
  explanation: Precision measures how many positive predictions were actually correct.
  chapter: Chapter 6
- id: 36
  question: Define recall (sensitivity, true positive rate).
  type: mc
  options:
  - A) TP / (TP + FP)
  - B) TP / (TP + FN)
  - C) TN / (TN + FN)
  - D) FP / (FP + TN)
  correct: B
  explanation: Recall measures what fraction of actual positives were correctly identified.
  chapter: Chapter 6
- id: 37
  question: Define specificity (true negative rate).
  type: mc
  options:
  - A) TP / (TP + FN)
  - B) TN / (TN + FP)
  - C) TN / (TN + FN)
  - D) FN / (FN + TP)
  correct: B
  explanation: Specificity measures what fraction of actual negatives were correctly
    identified.
  chapter: Chapter 6
- id: 38
  question: What is the F1-score and when is it useful?
  type: mc
  options:
  - A) Average of precision and recall
  - B) Harmonic mean of precision and recall, useful for imbalanced data
  - C) Product of precision and recall
  - D) Maximum of precision and recall
  correct: B
  explanation: F1-score is harmonic mean balancing precision and recall for imbalanced
    datasets.
  chapter: Chapter 6
- id: 39
  question: What does the F1-score balance?
  type: mc
  options:
  - A) Accuracy and speed
  - B) Precision and recall
  - C) Training and test performance
  - D) True positives and true negatives
  correct: B
  explanation: F1-score provides single metric combining both precision and recall
    performance.
  chapter: Chapter 6
- id: 40
  question: What is the ROC curve?
  type: mc
  options:
  - A) Plot of accuracy vs threshold
  - B) Plot of TPR vs FPR at different thresholds
  - C) Plot of precision vs recall
  - D) Plot of training vs test error
  correct: B
  explanation: ROC plots true positive rate vs false positive rate across all thresholds.
  chapter: Chapter 6
- id: 41
  question: What is AUC (Area Under Curve)?
  type: mc
  options:
  - A) Total model accuracy
  - B) Area under ROC curve, measure of classification ability
  - C) Average of all metrics
  - D) Number of correct predictions
  correct: B
  explanation: AUC measures overall classification ability; higher is better, ranges
    0 to 1.
  chapter: Chapter 6
- id: 42
  question: What does AUC = 0.5 indicate?
  type: mc
  options:
  - A) Perfect classification
  - B) Random guessing / no discrimination
  - C) 50% accuracy
  - D) Excellent performance
  correct: B
  explanation: AUC of 0.5 means model performs no better than random chance.
  chapter: Chapter 6
- id: 43
  question: What does AUC = 1.0 indicate?
  type: mc
  options:
  - A) Random performance
  - B) Perfect classification
  - C) 50% accuracy
  - D) Model overfitting
  correct: B
  explanation: Perfect classifier with AUC of 1.0 separates all classes correctly.
  chapter: Chapter 6
- id: 44
  question: When should you prioritize precision over recall?
  type: mc
  options:
  - A) When false positives are more costly than false negatives
  - B) When false negatives are more costly
  - C) When classes are balanced
  - D) Always prioritize precision
  correct: A
  explanation: When false positives are costly, like spam detection or fraud alerts.
  chapter: Chapter 6
- id: 45
  question: When should you prioritize recall over precision?
  type: mc
  options:
  - A) When false positives are more costly
  - B) When false negatives are more costly (e.g., disease detection)
  - C) When accuracy is high
  - D) Never prioritize recall
  correct: B
  explanation: When missing positives is costly, like disease detection or safety
    monitoring.
  chapter: Chapter 6
- id: 46
  question: What is a hyperparameter?
  type: mc
  options:
  - A) A parameter learned during training
  - B) A parameter set before training that controls learning
  - C) The model's prediction
  - D) The training data size
  correct: B
  explanation: Hyperparameter is set before training and controls the learning algorithm
    behavior.
  chapter: Chapter 7
- id: 47
  question: What is cross-validation?
  type: mc
  options:
  - A) Training on entire dataset
  - B) Splitting data into folds for robust evaluation
  - C) Testing on training data
  - D) Validating feature names
  correct: B
  explanation: Cross-validation splits data into multiple folds for more robust performance
    estimation.
  chapter: Chapter 7
- id: 48
  question: What is K-fold cross-validation?
  type: mc
  options:
  - A) Using K features
  - B) Splitting data into K folds, training on K-1, testing on 1
  - C) Running K models
  - D) Training for K epochs
  correct: B
  explanation: Data divided into K parts; train on K-1, test on 1, repeat K times.
  chapter: Chapter 7
- id: 49
  question: Why use cross-validation instead of a single train/test split?
  type: mc
  options:
  - A) It's faster
  - B) It provides more robust performance estimates
  - C) It requires less data
  - D) It improves accuracy
  correct: B
  explanation: Reduces variance in performance estimates and uses all data for testing.
  chapter: Chapter 7
- id: 50
  question: What is GridSearchCV?
  type: mc
  options:
  - A) A plotting function
  - B) Exhaustive search over hyperparameter grid with CV
  - C) A data preprocessing tool
  - D) A feature selection method
  correct: B
  explanation: Exhaustively searches hyperparameter combinations using cross-validation
    to find best settings.
  chapter: Chapter 7
- id: 51
  question: What is the regularization parameter C in logistic regression?
  type: mc
  options:
  - A) Number of classes
  - B) Inverse of regularization strength
  - C) Learning rate
  - D) Number of iterations
  correct: B
  explanation: C controls regularization strength; smaller C means stronger regularization.
  chapter: Chapter 7
- id: 52
  question: What happens when C is very small?
  type: mc
  options:
  - A) No regularization
  - B) Strong regularization, simpler model
  - C) Model becomes more complex
  - D) Training fails
  correct: B
  explanation: Small C applies strong regularization, shrinking coefficients toward
    zero for simplicity.
  chapter: Chapter 7
- id: 53
  question: What happens when C is very large?
  type: mc
  options:
  - A) Strong regularization
  - B) Weak regularization, more complex model
  - C) Model cannot fit
  - D) All coefficients become zero
  correct: B
  explanation: Large C applies weak regularization, allowing larger coefficients and
    more complexity.
  chapter: Chapter 7
- id: 54
  question: What is the purpose of stratification in train_test_split?
  type: mc
  options:
  - A) To randomize data
  - B) To preserve class proportions in splits
  - C) To increase dataset size
  - D) To normalize features
  correct: B
  explanation: Stratification maintains the same class proportions in both train and
    test sets.
  chapter: Chapter 7
- id: 55
  question: Why set random_state in train_test_split?
  type: mc
  options:
  - A) To improve accuracy
  - B) To ensure reproducibility of splits
  - C) To increase randomness
  - D) It's required for the function to work
  correct: B
  explanation: Random state ensures same split each run for reproducible and debuggable
    results.
  chapter: Chapter 7
- id: 56
  question: What is class imbalance?
  type: mc
  options:
  - A) Features with different scales
  - B) Unequal number of samples across classes
  - C) Model bias
  - D) Overlapping classes
  correct: B
  explanation: One class has significantly fewer samples than others in the dataset.
  chapter: Chapter 8
- id: 57
  question: What does class_weight='balanced' do?
  type: mc
  options:
  - A) Removes minority class
  - B) Automatically adjusts weights inversely proportional to class frequencies
  - C) Balances feature scales
  - D) Creates equal-sized classes
  correct: B
  explanation: Automatically assigns higher weights to minority class to balance importance.
  chapter: Chapter 8
- id: 58
  question: How does class weighting affect the model?
  type: mc
  options:
  - A) Increases accuracy only
  - B) Penalizes misclassification of minority class more
  - C) Removes all majority class samples
  - D) Has no effect on predictions
  correct: B
  explanation: Increases penalty for minority class misclassification, improving minority
    class recall.
  chapter: Chapter 8
- id: 59
  question: What is the probability threshold in classification?
  type: mc
  options:
  - A) Minimum training accuracy
  - B) Cutoff for converting probabilities to class labels (default 0.5)
  - C) Maximum number of iterations
  - D) The regularization strength
  correct: B
  explanation: Probability threshold determines cutoff for converting probabilities
    to class predictions.
  chapter: Chapter 8
- id: 60
  question: Why might you change the default 0.5 threshold?
  type: mc
  options:
  - A) To improve speed
  - B) To adjust precision-recall trade-off for specific needs
  - C) It must always be 0.5
  - D) To reduce model complexity
  correct: B
  explanation: Adjust threshold to favor precision or recall based on specific problem
    needs.
  chapter: Chapter 8
- id: 61
  question: What is SMOTE?
  type: mc
  options:
  - A) A regularization technique
  - B) Synthetic Minority Over-sampling Technique
  - C) A feature selection method
  - D) A type of neural network
  correct: B
  explanation: SMOTE generates synthetic minority class samples using nearest neighbor
    interpolation.
  chapter: Chapter 8
- id: 62
  question: What are the trade-offs of oversampling the minority class?
  type: mc
  options:
  - A) No trade-offs, always beneficial
  - B) Risk of overfitting to minority class
  - C) Decreases training time
  - D) Removes all bias
  correct: B
  explanation: Creating synthetic samples may lead to overfitting on minority class
    patterns.
  chapter: Chapter 8
- id: 63
  question: What are the trade-offs of undersampling the majority class?
  type: mc
  options:
  - A) Always improves performance
  - B) Loss of potentially useful information
  - C) Increases dataset size
  - D) No trade-offs
  correct: B
  explanation: Removing majority samples discards potentially useful information from
    the dataset.
  chapter: Chapter 8
- id: 64
  question: How does changing threshold affect precision and recall?
  type: mc
  options:
  - A) They always move together
  - B) Increasing threshold typically increases precision, decreases recall
  - C) Threshold doesn't affect metrics
  - D) Only affects accuracy
  correct: B
  explanation: Higher threshold increases precision but decreases recall; opposite
    for lower threshold.
  chapter: Chapter 8
- id: 65
  question: What is the precision-recall trade-off?
  type: mc
  options:
  - A) Precision and recall are always equal
  - B) Improving one often decreases the other
  - C) They are independent metrics
  - D) Trade-off only exists in multiclass
  correct: B
  explanation: Improving precision often reduces recall and vice versa; must find
    balance.
  chapter: Chapter 8
- id: 66
  question: Why standardize features for logistic regression?
  type: mc
  options:
  - A) It's required for the algorithm to work
  - B) For comparable coefficient magnitudes and better convergence
  - C) To increase accuracy
  - D) To reduce the number of features
  correct: B
  explanation: Makes coefficients comparable and improves optimization convergence
    in gradient descent.
  chapter: Chapter 9
- id: 67
  question: What does StandardScaler do?
  type: mc
  options:
  - A) Scales features to [0,1]
  - B) Transforms features to mean=0, std=1
  - C) Removes outliers
  - D) Selects important features
  correct: B
  explanation: Transforms each feature to have mean of zero and standard deviation
    of one.
  chapter: Chapter 9
- id: 68
  question: What is the difference between normalization and standardization?
  type: mc
  options:
  - A) They are the same
  - B) Normalization scales to [0,1], standardization to mean=0 std=1
  - C) Normalization is better
  - D) Standardization is deprecated
  correct: B
  explanation: Normalization scales to 0-1 range; standardization centers at mean
    with unit variance.
  chapter: Chapter 9
- id: 69
  question: Should you fit the scaler on test data?
  type: mc
  options:
  - A) Yes, always fit on test data
  - B) No, only fit on training data to avoid data leakage
  - C) Fit on both training and test
  - D) It doesn't matter
  correct: B
  explanation: Prevents data leakage; only training data should inform preprocessing
    parameters.
  chapter: Chapter 9
- id: 70
  question: Why use pipelines for preprocessing?
  type: mc
  options:
  - A) To make code slower
  - B) To ensure consistent preprocessing and prevent data leakage
  - C) Pipelines are required by scikit-learn
  - D) To increase model complexity
  correct: B
  explanation: Ensures preprocessing steps applied consistently and prevents data
    leakage errors.
  chapter: Chapter 9
- id: 71
  question: What is multiclass classification?
  type: mc
  options:
  - A) Classification with multiple features
  - B) Classification with more than two classes
  - C) Classification using multiple models
  - D) Binary classification repeated
  correct: B
  explanation: Classification problem with three or more mutually exclusive class
    categories.
  chapter: Chapter 13
- id: 72
  question: What is the difference between binary and multiclass?
  type: mc
  options:
  - A) Binary uses two features, multiclass uses more
  - B) Binary has two classes, multiclass has three or more
  - C) Binary is more accurate
  - D) No difference
  correct: B
  explanation: Binary has two classes; multiclass has three or more possible categories.
  chapter: Chapter 13
- id: 73
  question: What is one-vs-rest (OvR) strategy?
  type: mc
  options:
  - A) Train one model for all classes
  - B) Train one binary classifier per class vs all others
  - C) Train models in sequence
  - D) Use only one feature
  correct: B
  explanation: Trains one binary classifier per class versus all other classes combined.
  chapter: Chapter 13
- id: 74
  question: What is one-vs-one (OvO) strategy?
  type: mc
  options:
  - A) One model for all pairs of classes
  - B) One model for each class
  - C) One model total
  - D) One feature per class
  correct: A
  explanation: Trains one binary classifier for each pair of classes.
  chapter: Chapter 13
- id: 75
  question: What is multinomial logistic regression?
  type: mc
  options:
  - A) Multiple binary logistic regressions
  - B) Direct multiclass extension using softmax
  - C) A type of neural network
  - D) Cannot handle more than 2 classes
  correct: B
  explanation: Direct multiclass extension using softmax function for probability
    distribution.
  chapter: Chapter 13
- id: 76
  question: How many sets of coefficients in multiclass LR with K classes?
  type: mc
  options:
  - A) 1
  - B) K-1
  - C) K
  - D) 2K
  correct: C
  explanation: K coefficient sets, one for each class in multiclass logistic regression.
  chapter: Chapter 14
- id: 77
  question: How does multiclass LR make predictions?
  type: mc
  options:
  - A) Randomly selects a class
  - B) Calculates probabilities for all classes, selects highest
  - C) Uses majority voting
  - D) Predicts first class only
  correct: B
  explanation: Computes class probabilities using softmax, predicts class with highest
    probability.
  chapter: Chapter 14
- id: 78
  question: What is the softmax function?
  type: mc
  options:
  - A) A type of regularization
  - B) Generalizes sigmoid to multiple classes, outputs probability distribution
  - C) A loss function
  - D) A feature scaling method
  correct: B
  explanation: Softmax converts raw scores into probability distribution summing to
    one.
  chapter: Chapter 14
- id: 79
  question: How do you interpret multiclass confusion matrix?
  type: mc
  options:
  - A) Same as binary, just 2x2
  - B) K×K matrix where entry (i,j) shows actual class i predicted as j
  - C) Cannot interpret multiclass confusion matrix
  - D) Only diagonal matters
  correct: B
  explanation: Diagonal shows correct predictions; off-diagonal shows which classes
    are confused.
  chapter: Chapter 14
- id: 80
  question: What is macro-average vs weighted-average in multiclass metrics?
  type: mc
  options:
  - A) They are the same
  - 'B) Macro: unweighted mean across classes; Weighted: by class support'
  - C) Macro is always better
  - D) Weighted ignores minority classes
  correct: B
  explanation: Macro averages metrics equally; weighted averages by number of samples
    per class.
  chapter: Chapter 14
- id: 81
  question: What is the Iris dataset used for?
  type: mc
  options:
  - A) Binary classification
  - B) 3-class flower species classification
  - C) Regression
  - D) Clustering only
  correct: B
  explanation: Classic dataset for 3-class flower species classification using petal
    measurements.
  chapter: Chapter 15
- id: 82
  question: How many classes in the Wine dataset?
  type: mc
  options:
  - A) 2
  - B) 3
  - C) 5
  - D) 10
  correct: B
  explanation: Wine dataset contains three different wine cultivar classes.
  chapter: Chapter 15
- id: 83
  question: What is the Digits dataset?
  type: mc
  options:
  - A) Binary classification of digits
  - B) 10-class handwritten digit recognition (0-9)
  - C) Regression on numbers
  - D) Only classifies 0 and 1
  correct: B
  explanation: Dataset of 8x8 pixel handwritten digits for 10-class classification.
  chapter: Chapter 15
- id: 84
  question: Why is multiclass classification harder than binary?
  type: mc
  options:
  - A) It's actually easier
  - B) More classes means more complex decision boundaries
  - C) Binary classification doesn't work
  - D) No difference in difficulty
  correct: B
  explanation: More classes mean more complex decision boundaries and confusion between
    classes.
  chapter: Chapter 15
- id: 85
  question: When would you use multiclass instead of multiple binary classifiers?
  type: mc
  options:
  - A) Never use multiclass
  - B) When classes are mutually exclusive and exhaustive
  - C) Always use binary classifiers
  - D) Only for 2 classes
  correct: B
  explanation: When outcomes are mutually exclusive categories, not independent binary
    decisions.
  chapter: Chapter 15
- id: 86
  question: How does a decision tree make predictions?
  type: mc
  options:
  - A) Using linear equations
  - B) Following if-then rules from root to leaf
  - C) Calculating probabilities only
  - D) Random selection
  correct: B
  explanation: Follows if-then decision rules from root to leaf node containing prediction.
  chapter: Chapter 16
- id: 87
  question: What is a split in a decision tree?
  type: mc
  options:
  - A) Dividing training and test data
  - B) Decision point that partitions data based on a feature
  - C) Removing outliers
  - D) Combining features
  correct: B
  explanation: Split divides data into subsets based on a feature threshold.
  chapter: Chapter 16
- id: 88
  question: What is a leaf node?
  type: mc
  options:
  - A) The root of the tree
  - B) Terminal node containing class prediction
  - C) A split point
  - D) The entire tree
  correct: B
  explanation: Terminal node that contains the final class prediction or value.
  chapter: Chapter 16
- id: 89
  question: What is tree depth?
  type: mc
  options:
  - A) Number of features
  - B) Longest path from root to leaf
  - C) Number of samples
  - D) Total number of nodes
  correct: B
  explanation: Maximum number of splits from root to any leaf node.
  chapter: Chapter 16
- id: 90
  question: What is the Gini impurity?
  type: mc
  options:
  - A) Measure of tree size
  - B) Measure of class mixture/impurity in a node
  - C) Number of mistakes
  - D) Training accuracy
  correct: B
  explanation: Gini measures probability of incorrectly classifying a randomly chosen
    element.
  chapter: Chapter 16
- id: 91
  question: What is entropy in decision trees?
  type: mc
  options:
  - A) Tree depth
  - B) Measure of disorder/uncertainty in class labels
  - C) Number of splits
  - D) Prediction accuracy
  correct: B
  explanation: Entropy measures uncertainty or disorder in the class distribution.
  chapter: Chapter 16
- id: 92
  question: What is information gain?
  type: mc
  options:
  - A) Number of new samples
  - B) Reduction in entropy from a split
  - C) Increase in accuracy
  - D) Tree growth rate
  correct: B
  explanation: Reduction in entropy achieved by splitting on a particular feature.
  chapter: Chapter 16
- id: 93
  question: How does a tree choose which feature to split on?
  type: mc
  options:
  - A) Random selection
  - B) Feature with highest information gain or lowest impurity
  - C) First feature in dataset
  - D) Most correlated feature
  correct: B
  explanation: Chooses feature that maximizes information gain or minimizes impurity
    after split.
  chapter: Chapter 16
- id: 94
  question: What is overfitting in decision trees?
  type: mc
  options:
  - A) Tree is too small
  - B) Tree memorizes training data, poor generalization
  - C) Perfect performance
  - D) Tree cannot make predictions
  correct: B
  explanation: Tree learns training data too specifically, capturing noise instead
    of patterns.
  chapter: Chapter 16
- id: 95
  question: Why do deep trees tend to overfit?
  type: mc
  options:
  - A) They are too simple
  - B) They create overly specific rules for training data
  - C) They cannot learn patterns
  - D) Deep trees are always better
  correct: B
  explanation: Deep trees create overly specific rules that don't generalize to new
    data.
  chapter: Chapter 16
- id: 96
  question: What is pruning?
  type: mc
  options:
  - A) Growing the tree larger
  - B) Removing branches to reduce overfitting
  - C) Adding more features
  - D) Increasing tree depth
  correct: B
  explanation: Removing tree branches to reduce complexity and prevent overfitting.
  chapter: Chapter 17
- id: 97
  question: What is pre-pruning?
  type: mc
  options:
  - A) Pruning after tree is fully grown
  - B) Stopping tree growth early based on criteria
  - C) Removing the root
  - D) Growing tree first then pruning
  correct: B
  explanation: Stopping tree growth early based on criteria like depth or samples.
  chapter: Chapter 17
- id: 98
  question: What is post-pruning?
  type: mc
  options:
  - A) Stopping growth early
  - B) Growing full tree then removing branches
  - C) Never pruning
  - D) Pruning before training
  correct: B
  explanation: Growing full tree first, then removing branches based on validation
    performance.
  chapter: Chapter 17
- id: 99
  question: What is the max_depth hyperparameter?
  type: mc
  options:
  - A) Maximum number of features
  - B) Maximum tree depth allowed
  - C) Maximum number of samples
  - D) Maximum accuracy
  correct: B
  explanation: Limits maximum depth of tree to prevent overfitting.
  chapter: Chapter 17
- id: 100
  question: What is min_samples_split?
  type: mc
  options:
  - A) Minimum samples in leaf
  - B) Minimum samples required to split a node
  - C) Minimum tree depth
  - D) Minimum accuracy
  correct: B
  explanation: Minimum samples required in a node to consider splitting it further.
  chapter: Chapter 17
- id: 101
  question: What is min_samples_leaf?
  type: mc
  options:
  - A) Minimum samples to split
  - B) Minimum samples required in a leaf node
  - C) Minimum features
  - D) Minimum depth
  correct: B
  explanation: Minimum samples that must remain in each leaf node.
  chapter: Chapter 17
- id: 102
  question: What is min_impurity_decrease?
  type: mc
  options:
  - A) Maximum impurity allowed
  - B) Minimum impurity reduction required for a split
  - C) Minimum number of leaves
  - D) Minimum accuracy gain
  correct: B
  explanation: Minimum reduction in impurity required to perform a split.
  chapter: Chapter 17
- id: 103
  question: What is cost-complexity pruning (CCP)?
  type: mc
  options:
  - A) Pre-pruning method
  - B) Post-pruning using penalty for tree complexity
  - C) Feature selection
  - D) Data preprocessing
  correct: B
  explanation: Post-pruning method that penalizes tree complexity using alpha parameter.
  chapter: Chapter 17
- id: 104
  question: What is the alpha parameter in CCP?
  type: mc
  options:
  - A) Learning rate
  - B) Complexity penalty weight
  - C) Number of trees
  - D) Split criterion
  correct: B
  explanation: Alpha controls trade-off between tree complexity and training accuracy.
  chapter: Chapter 17
- id: 105
  question: How do you choose the best alpha for CCP?
  type: mc
  options:
  - A) Always use alpha=1
  - B) Cross-validation to find optimal complexity
  - C) Random selection
  - D) Use largest alpha
  correct: B
  explanation: Use cross-validation to find alpha that minimizes validation error.
  chapter: Chapter 17
- id: 106
  question: What is ensemble learning?
  type: mc
  options:
  - A) Training one large model
  - B) Combining multiple models for better predictions
  - C) Using multiple features
  - D) Training on multiple datasets separately
  correct: B
  explanation: Combining predictions from multiple models to improve overall performance.
  chapter: Chapter 18
- id: 107
  question: What is bagging?
  type: mc
  options:
  - A) Removing bad samples
  - B) Bootstrap Aggregating - training on random samples with replacement
  - C) Selecting best features
  - D) Combining test results
  correct: B
  explanation: Training multiple models on random samples with replacement, then averaging
    predictions.
  chapter: Chapter 18
- id: 108
  question: How does Random Forest work?
  type: mc
  options:
  - A) One deep decision tree
  - B) Ensemble of decision trees with random feature subsets
  - C) Linear combination of features
  - D) Sequential tree building
  correct: B
  explanation: Ensemble of decision trees using bootstrap samples and random feature
    subsets.
  chapter: Chapter 18
- id: 109
  question: What is bootstrap sampling?
  type: mc
  options:
  - A) Sampling without replacement
  - B) Random sampling with replacement
  - C) Taking first N samples
  - D) Stratified sampling only
  correct: B
  explanation: Random sampling with replacement; same sample can be selected multiple
    times.
  chapter: Chapter 18
- id: 110
  question: What is the n_estimators parameter?
  type: mc
  options:
  - A) Number of features
  - B) Number of trees in the ensemble
  - C) Tree depth
  - D) Number of samples
  correct: B
  explanation: Number of decision trees in the random forest ensemble.
  chapter: Chapter 18
- id: 111
  question: What is max_features in Random Forest?
  type: mc
  options:
  - A) Total features in dataset
  - B) Number of features considered for each split
  - C) Maximum tree depth
  - D) Number of trees
  correct: B
  explanation: Number of features randomly selected when finding best split.
  chapter: Chapter 18
- id: 112
  question: Why does Random Forest reduce overfitting?
  type: mc
  options:
  - A) Uses smaller datasets
  - B) Averaging diverse trees reduces variance
  - C) Uses fewer features total
  - D) Simpler than single tree
  correct: B
  explanation: Averaging many diverse trees reduces variance and overfitting.
  chapter: Chapter 18
- id: 113
  question: What is feature importance in Random Forest?
  type: mc
  options:
  - A) Number of times feature appears
  - B) Average impurity decrease across all trees for each feature
  - C) Feature correlation
  - D) Feature mean value
  correct: B
  explanation: Measures each feature's average contribution to reducing impurity across
    all trees.
  chapter: Chapter 18
- id: 114
  question: How does Random Forest handle missing values?
  type: mc
  options:
  - A) Automatically in sklearn (requires imputation)
  - B) Sklearn Random Forest requires preprocessing for missing values
  - C) Deletes rows with missing values
  - D) Replaces with zeros
  correct: B
  explanation: Sklearn requires imputation; some implementations can handle missing
    values natively.
  chapter: Chapter 18
- id: 115
  question: What are out-of-bag (OOB) samples?
  type: mc
  options:
  - A) Test set samples
  - B) Samples not selected in bootstrap sample for a tree
  - C) Outliers
  - D) Validation set
  correct: B
  explanation: Samples not selected in a particular bootstrap sample; used for validation.
  chapter: Chapter 18
- id: 116
  question: What is boosting?
  type: mc
  options:
  - A) Training identical models
  - B) Sequential training where each model corrects previous errors
  - C) Increasing dataset size
  - D) Removing weak features
  correct: B
  explanation: Sequential ensemble where each model focuses on correcting previous
    models' errors.
  chapter: Chapter 19
- id: 117
  question: How does boosting differ from bagging?
  type: mc
  options:
  - A) No difference
  - B) Boosting is sequential, bagging is parallel
  - C) Bagging is always better
  - D) Boosting uses more data
  correct: B
  explanation: Boosting builds models sequentially; bagging builds all models independently
    in parallel.
  chapter: Chapter 19
- id: 118
  question: What is the learning_rate parameter in boosting?
  type: mc
  options:
  - A) Speed of training
  - B) Weight of each tree's contribution
  - C) Number of iterations
  - D) Tree depth
  correct: B
  explanation: Controls how much each tree contributes; lower rate needs more trees.
  chapter: Chapter 19
- id: 119
  question: What is the relationship between n_estimators and learning_rate?
  type: mc
  options:
  - A) Independent parameters
  - B) Lower learning_rate typically needs more estimators
  - C) Must be equal
  - D) Inversely proportional always
  correct: B
  explanation: Lower learning rate requires more estimators to achieve same performance.
  chapter: Chapter 19
- id: 120
  question: Why does boosting often outperform bagging?
  type: mc
  options:
  - A) Uses more data
  - B) Focuses on hard-to-classify examples
  - C) Faster training
  - D) Simpler models
  correct: B
  explanation: Focuses learning on difficult cases that previous models misclassified.
  chapter: Chapter 19
- id: 121
  question: What is the risk of boosting?
  type: mc
  options:
  - A) Underfitting only
  - B) Overfitting if too many iterations
  - C) Cannot converge
  - D) No risks
  correct: B
  explanation: Too many iterations can overfit to training data, especially with noise.
  chapter: Chapter 19
- id: 122
  question: What is the friedman_mse criterion?
  type: mc
  options:
  - A) A pruning method
  - B) Mean squared error with Friedman's improvement for boosting
  - C) Feature importance measure
  - D) Learning rate formula
  correct: B
  explanation: Splitting criterion optimized for gradient boosting algorithms.
  chapter: Chapter 19
- id: 123
  question: Does GradientBoostingClassifier have class_weight parameter?
  type: mc
  options:
  - A) Yes, same as LogisticRegression
  - B) No, it doesn't have class_weight parameter
  - C) Only in newer versions
  - D) Yes, but deprecated
  correct: B
  explanation: GradientBoostingClassifier doesn't have class_weight; use sample_weight
    in fit instead.
  chapter: Chapter 19
- id: 124
  question: When should you use Random Forest vs Gradient Boosting?
  type: mc
  options:
  - A) Always use Random Forest
  - B) RF for quick baseline, GB for squeezing performance
  - C) GB is always better
  - D) No difference
  correct: B
  explanation: Random Forest for quick robust baseline; Gradient Boosting for maximum
    performance tuning.
  chapter: Chapter 19
- id: 125
  question: What is early stopping in boosting?
  type: mc
  options:
  - A) Starting late
  - B) Stopping training when validation performance stops improving
  - C) Training fewer trees always
  - D) Pruning trees early
  correct: B
  explanation: Stops training when validation error stops decreasing to prevent overfitting.
  chapter: Chapter 19
- id: 126
  question: How do you import NumPy with standard alias?
  type: mc
  options:
  - A) import numpy
  - B) import numpy as np
  - C) from numpy import all
  - D) import np
  correct: B
  explanation: 'Standard convention: import numpy as np for brevity.'
  chapter: All chapters (imports)
- id: 127
  question: How do you create a NumPy array from a list?
  type: mc
  options:
  - A) np.list([1,2,3])
  - B) np.array([1,2,3])
  - C) np.create([1,2,3])
  - D) numpy.list([1,2,3])
  correct: B
  explanation: np.array() converts Python lists to NumPy arrays.
  chapter: Chapter 1
- id: 128
  question: How do you create an array of zeros with shape (5, 3)?
  type: mc
  options:
  - A) np.zeros(5,3)
  - B) np.zeros((5, 3))
  - C) np.zero((5, 3))
  - D) np.zeros[5,3]
  correct: B
  explanation: Use tuple (5, 3) to specify shape with 5 rows, 3 columns.
  chapter: Data preprocessing
- id: 129
  question: How do you create an array of ones?
  type: mc
  options:
  - A) np.one((2,3))
  - B) np.ones((2,3))
  - C) np.ones(2,3)
  - D) np.create_ones((2,3))
  correct: B
  explanation: np.ones() creates array filled with ones in specified shape.
  chapter: Data preprocessing
- id: 130
  question: How do you create a range of numbers from 0 to 10?
  type: mc
  options:
  - A) np.range(0, 11)
  - B) np.arange(11)
  - C) np.sequence(0, 10)
  - D) np.array(range(10))
  correct: B
  explanation: np.arange(11) creates array [0,1,2,...,10]; 11 is exclusive upper bound.
  chapter: Visualization chapters
- id: 131
  question: How do you reshape a 1D array to 2D?
  type: mc
  options:
  - A) arr.shape((5,2))
  - B) arr.reshape((5, 2))
  - C) arr.resize((5, 2))
  - D) arr.change_shape((5,2))
  correct: B
  explanation: reshape() changes array dimensions; requires compatible total number
    of elements.
  chapter: Model fitting chapters
- id: 132
  question: What does .reshape(-1, 1) do?
  type: mc
  options:
  - A) Creates a 2D array with 1 row
  - B) Converts to column vector (2D with 1 column)
  - C) Flattens the array
  - D) Removes dimension
  correct: B
  explanation: 'Creates column vector: -1 infers rows, 1 specifies single column.'
  chapter: Model input preparation
- id: 133
  question: How do you calculate the mean of an array?
  type: mc
  options:
  - A) arr.average()
  - B) arr.mean() or np.mean(arr)
  - C) arr.avg()
  - D) np.average(arr) only
  correct: B
  explanation: Both arr.mean() and np.mean(arr) calculate the arithmetic mean.
  chapter: Chapter 1 (probability)
- id: 134
  question: How do you calculate the sum of an array?
  type: mc
  options:
  - A) arr.total()
  - B) arr.sum() or np.sum(arr)
  - C) arr.add()
  - D) np.total(arr)
  correct: B
  explanation: Both arr.sum() and np.sum(arr) calculate the total sum.
  chapter: Metric calculations
- id: 135
  question: How do you find the maximum value in an array?
  type: mc
  options:
  - A) arr.maximum()
  - B) arr.max() or np.max(arr)
  - C) arr.largest()
  - D) np.maximum(arr)
  correct: B
  explanation: Both arr.max() and np.max(arr) return the maximum value.
  chapter: Data exploration
- id: 136
  question: How do you create a boolean mask where values > 5?
  type: mc
  options:
  - A) arr.filter(> 5)
  - B) arr > 5
  - C) arr.greater(5)
  - D) np.where(arr, 5)
  correct: B
  explanation: Comparison operators create boolean arrays for filtering or counting.
  chapter: Data filtering
- id: 137
  question: How do you count True values in a boolean array?
  type: mc
  options:
  - A) bool_arr.count()
  - B) np.sum(bool_arr) or bool_arr.sum()
  - C) bool_arr.total()
  - D) len(bool_arr)
  correct: B
  explanation: Sum treats True as 1 and False as 0, counting True values.
  chapter: Metric calculations
- id: 138
  question: How do you use np.where() for conditional selection?
  type: mc
  options:
  - A) np.where(arr > 0)
  - B) np.where(condition, value_if_true, value_if_false)
  - C) np.where(arr, value)
  - D) np.select(condition)
  correct: B
  explanation: np.where(condition, x, y) returns x where condition True, else y.
  chapter: Chapter 8 (threshold adjustment)
- id: 139
  question: How do you combine boolean arrays with &, |?
  type: mc
  options:
  - A) arr1 and arr2, arr1 or arr2
  - B) (arr1 > 0) & (arr2 < 10)
  - C) arr1 && arr2, arr1 || arr2
  - D) np.and(arr1, arr2)
  correct: B
  explanation: Use & for AND, | for OR; parentheses required for compound conditions.
  chapter: Data filtering
- id: 140
  question: What does np.any() do?
  type: mc
  options:
  - A) Returns all True values
  - B) Returns True if any element is True
  - C) Returns first True value
  - D) Counts True values
  correct: B
  explanation: Returns True if at least one element in array is True.
  chapter: Data validation
- id: 141
  question: How do you import pandas with standard alias?
  type: mc
  options:
  - A) import pandas
  - B) import pandas as pd
  - C) from pandas import all
  - D) import pd
  correct: B
  explanation: 'Standard convention: import pandas as pd for brevity.'
  chapter: All chapters (imports)
- id: 142
  question: How do you read a CSV file from a URL?
  type: mc
  options:
  - A) pd.read(url)
  - B) pd.read_csv(url)
  - C) pd.load_csv(url)
  - D) pd.from_csv(url)
  correct: B
  explanation: pd.read_csv() works with URLs and local file paths.
  chapter: All dataset loading
- id: 143
  question: How do you display first 5 rows of a DataFrame?
  type: mc
  options:
  - A) df.first(5)
  - B) df.head()
  - C) df.show(5)
  - D) df.top(5)
  correct: B
  explanation: df.head() shows first 5 rows by default; optional argument for different
    number.
  chapter: Data exploration
- id: 144
  question: What does .info() show?
  type: mc
  options:
  - A) Only data types
  - 'B) Summary: columns, dtypes, non-null counts, memory'
  - C) Only first few rows
  - D) Statistical summary
  correct: B
  explanation: Shows column names, data types, non-null counts, and memory usage.
  chapter: Data exploration
- id: 145
  question: What does .describe() show?
  type: mc
  options:
  - A) Data types
  - B) Statistical summary (count, mean, std, min, max, quartiles)
  - C) Column names
  - D) Missing values
  correct: B
  explanation: Shows count, mean, standard deviation, min, quartiles, and max for
    numeric columns.
  chapter: Data exploration
- id: 146
  question: How do you select a single column?
  type: mc
  options:
  - A) df.column_name or df['column_name']
  - B) df.get('column_name')
  - C) df.select('column_name')
  - D) df:column_name
  correct: A
  explanation: Both df.column_name and df['column_name'] select a single column Series.
  chapter: Feature selection
- id: 147
  question: How do you select multiple columns?
  type: mc
  options:
  - A) df.col1, col2
  - B) df[['col1', 'col2']]
  - C) df['col1', 'col2']
  - D) df.get(['col1', 'col2'])
  correct: B
  explanation: Double brackets return DataFrame with selected columns.
  chapter: Feature selection
- id: 148
  question: How do you select rows using iloc?
  type: mc
  options:
  - A) df.iloc['row_name']
  - B) df.iloc[0:5] or df.iloc[0]
  - C) df.iloc('row_name')
  - 'D) df.iloc{''row'': 0}'
  correct: B
  explanation: iloc uses integer positions; row 0 is first, row 5 is sixth.
  chapter: Data subsetting
- id: 149
  question: How do you select rows using loc?
  type: mc
  options:
  - A) df.loc[0]
  - B) df.loc[row_label] or df.loc[condition]
  - C) df.loc(row_label)
  - D) df.loc{row_label}
  correct: B
  explanation: loc uses labels; can use boolean conditions for filtering.
  chapter: Data subsetting
- id: 150
  question: How do you filter rows based on a condition?
  type: mc
  options:
  - A) df.filter(df['col'] > 5)
  - B) df[df['col'] > 5]
  - C) df.where(df['col'] > 5)
  - D) df.select(df['col'] > 5)
  correct: B
  explanation: 'Boolean indexing: condition in brackets returns filtered DataFrame.'
  chapter: Data exploration
- id: 151
  question: How do you create dummy variables with pd.get_dummies()?
  type: mc
  options:
  - A) pd.dummy(df, columns=['col'])
  - B) pd.get_dummies(df, columns=['col'])
  - C) df.get_dummies(columns=['col'])
  - D) pd.create_dummies(df, 'col')
  correct: B
  explanation: Creates dummy variables for specified categorical columns.
  chapter: All preprocessing
- id: 152
  question: What does drop_first=True do in get_dummies()?
  type: mc
  options:
  - A) Drops first row
  - B) Drops first dummy column to avoid multicollinearity
  - C) Drops first feature
  - D) Drops missing values
  correct: B
  explanation: Drops one dummy column per category to avoid multicollinearity.
  chapter: Categorical encoding
- id: 153
  question: How do you drop columns from a DataFrame?
  type: mc
  options:
  - A) df.remove(['col'])
  - B) df.drop(['col'], axis=1) or df.drop(columns=['col'])
  - C) df.delete(['col'])
  - D) df.drop_column(['col'])
  correct: B
  explanation: axis=1 means drop columns; axis=0 would drop rows.
  chapter: Feature selection
- id: 154
  question: What does inplace=True mean?
  type: mc
  options:
  - A) Creates a copy
  - B) Modifies DataFrame in place, returns None
  - C) Returns new DataFrame
  - D) Validates the operation
  correct: B
  explanation: Modifies original DataFrame instead of returning new copy.
  chapter: Data manipulation
- id: 155
  question: How do you check for missing values?
  type: mc
  options:
  - A) df.missing()
  - B) df.isna() or df.isnull()
  - C) df.check_null()
  - D) df.find_missing()
  correct: B
  explanation: Both methods check for missing values; isna() is newer alias.
  chapter: Data quality checks
- id: 156
  question: What does .value_counts() do?
  type: mc
  options:
  - A) Counts total values
  - B) Returns frequency of unique values in a Series
  - C) Counts missing values
  - D) Counts all values
  correct: B
  explanation: Counts frequency of each unique value in descending order.
  chapter: Class distribution checks
- id: 157
  question: How do you get proportions instead of counts?
  type: mc
  options:
  - A) value_counts(proportion=True)
  - B) value_counts(normalize=True)
  - C) value_counts(percent=True)
  - D) value_counts()/len(df)
  correct: B
  explanation: normalize=True converts counts to proportions summing to 1.
  chapter: Probability calculations
- id: 158
  question: How do you sort value_counts() by index?
  type: mc
  options:
  - A) value_counts(sort=True)
  - B) value_counts().sort_index()
  - C) value_counts().sort()
  - D) value_counts().order()
  correct: B
  explanation: sort_index() sorts by the index (values) instead of counts.
  chapter: Ordered data exploration
- id: 159
  question: What does .unique() return?
  type: mc
  options:
  - A) Count of unique values
  - B) Array of unique values
  - C) Boolean mask
  - D) Frequency of values
  correct: B
  explanation: Returns array of unique values without frequencies.
  chapter: Category identification
- id: 160
  question: How do you group by a column and calculate mean?
  type: mc
  options:
  - A) df.group('col').mean()
  - B) df.groupby('col').mean()
  - C) df.groupby('col', mean=True)
  - D) df.mean(groupby='col')
  correct: B
  explanation: Groups by column, then calculates mean for each group.
  chapter: Group analysis
- id: 161
  question: How do you import matplotlib.pyplot with standard alias?
  type: mc
  options:
  - A) import matplotlib
  - B) import matplotlib.pyplot as plt
  - C) from matplotlib import pyplot
  - D) import plt
  correct: B
  explanation: 'Standard convention: import matplotlib.pyplot as plt for brevity.'
  chapter: All chapters (imports)
- id: 162
  question: How do you create a simple line plot?
  type: mc
  options:
  - A) plt.line(x, y)
  - B) plt.plot(x, y)
  - C) plt.draw(x, y)
  - D) plt.line_plot(x, y)
  correct: B
  explanation: plt.plot() creates line plot connecting points.
  chapter: Visualization chapters
- id: 163
  question: How do you create a scatter plot?
  type: mc
  options:
  - A) plt.plot(x, y, 'o')
  - B) plt.scatter(x, y)
  - C) plt.points(x, y)
  - D) plt.dot(x, y)
  correct: B
  explanation: plt.scatter() creates scatter plot with individual points.
  chapter: Data exploration
- id: 164
  question: How do you create a bar plot?
  type: mc
  options:
  - A) plt.bars(x, y)
  - B) plt.bar(x, height)
  - C) plt.barplot(x, y)
  - D) plt.column(x, y)
  correct: B
  explanation: plt.bar() creates bar chart; height parameter specifies bar heights.
  chapter: Distribution visualization
- id: 165
  question: How do you add labels to x and y axes?
  type: mc
  options:
  - A) plt.labels('x', 'y')
  - B) plt.xlabel('x'); plt.ylabel('y')
  - C) plt.set_labels('x', 'y')
  - D) plt.axis_labels('x', 'y')
  correct: B
  explanation: xlabel() and ylabel() add descriptive labels to axes.
  chapter: All visualizations
- id: 166
  question: How do you set figure size?
  type: mc
  options:
  - A) plt.size(10, 6)
  - B) plt.figure(figsize=(10, 6))
  - C) plt.set_size(10, 6)
  - D) plt.figsize(10, 6)
  correct: B
  explanation: figsize tuple (width, height) in inches sets figure size.
  chapter: All visualizations
- id: 167
  question: How do you add a title to a plot?
  type: mc
  options:
  - A) plt.header('Title')
  - B) plt.title('Title')
  - C) plt.set_title('Title')
  - D) plt.name('Title')
  correct: B
  explanation: plt.title() adds title text above the plot.
  chapter: All visualizations
- id: 168
  question: How do you add a legend?
  type: mc
  options:
  - A) plt.show_legend()
  - B) plt.legend()
  - C) plt.add_legend()
  - D) plt.key()
  correct: B
  explanation: plt.legend() displays legend box showing labels from plot commands.
  chapter: Multi-series plots
- id: 169
  question: How do you add a grid?
  type: mc
  options:
  - A) plt.show_grid()
  - B) plt.grid(True) or plt.grid()
  - C) plt.add_grid()
  - D) plt.gridlines()
  correct: B
  explanation: plt.grid() or plt.grid(True) adds gridlines to plot.
  chapter: All visualizations
- id: 170
  question: How do you save a figure to file?
  type: mc
  options:
  - A) plt.save('file.png')
  - B) plt.savefig('file.png')
  - C) plt.export('file.png')
  - D) plt.write('file.png')
  correct: B
  explanation: plt.savefig() saves current figure to file; supports PNG, PDF, SVG
    formats.
  chapter: Report generation
- id: 171
  question: How do you create subplots (2 rows, 2 cols)?
  type: mc
  options:
  - A) plt.subplot(2, 2)
  - B) fig, axes = plt.subplots(2, 2)
  - C) plt.subplots((2, 2))
  - D) plt.create_subplots(2, 2)
  correct: B
  explanation: Returns figure and array of axes objects for subplots.
  chapter: Multi-panel visualizations
- id: 172
  question: How do you access a specific subplot in axes array?
  type: mc
  options:
  - A) axes.get(0, 0)
  - B) axes[0, 0] or axes[0][0]
  - C) axes(0, 0)
  - D) axes.subplot(0, 0)
  correct: B
  explanation: Indexing axes array accesses individual subplot for plotting.
  chapter: Multi-panel visualizations
- id: 173
  question: How do you adjust spacing between subplots?
  type: mc
  options:
  - A) plt.spacing()
  - B) plt.tight_layout() or plt.subplots_adjust()
  - C) plt.adjust_space()
  - D) plt.set_spacing()
  correct: B
  explanation: tight_layout() auto-adjusts; subplots_adjust() for manual spacing control.
  chapter: Layout management
- id: 174
  question: How do you create horizontal and vertical lines?
  type: mc
  options:
  - A) plt.line(x, 'h')
  - B) plt.axhline(y), plt.axvline(x)
  - C) plt.hline(y), plt.vline(x)
  - D) plt.draw_line(x, y)
  correct: B
  explanation: axhline draws horizontal line at y; axvline draws vertical line at
    x.
  chapter: Reference lines
- id: 175
  question: How do you set axis limits?
  type: mc
  options:
  - A) plt.limits(0, 10)
  - B) plt.xlim(0, 10); plt.ylim(0, 10)
  - C) plt.set_limits(0, 10)
  - D) plt.axis_limits(0, 10)
  correct: B
  explanation: xlim() and ylim() set axis ranges for better visualization.
  chapter: Plot customization
- id: 176
  question: How do you import train_test_split?
  type: mc
  options:
  - A) from sklearn import train_test_split
  - B) from sklearn.model_selection import train_test_split
  - C) from sklearn.split import train_test_split
  - D) import sklearn.train_test_split
  correct: B
  explanation: Import train_test_split from sklearn.model_selection submodule.
  chapter: All chapters with modeling
- id: 177
  question: What are the main parameters of train_test_split()?
  type: mc
  options:
  - A) X only
  - B) X, y, test_size, random_state, stratify
  - C) data, labels
  - D) features, target, split
  correct: B
  explanation: 'Key parameters: X, y, test_size, random_state, stratify for balanced
    splits.'
  chapter: Data splitting
- id: 178
  question: What does test_size=0.2 mean?
  type: mc
  options:
  - A) 2% for testing
  - B) 20% for testing, 80% for training
  - C) 0.2 samples for testing
  - D) 20 samples for testing
  correct: B
  explanation: 20% of data for testing, 80% for training.
  chapter: Data splitting
- id: 179
  question: What does random_state do?
  type: mc
  options:
  - A) Increases randomness
  - B) Sets seed for reproducible random splits
  - C) Randomizes features
  - D) Shuffles data
  correct: B
  explanation: Sets random seed for reproducible splits across multiple runs.
  chapter: Reproducibility
- id: 180
  question: What does stratify parameter do?
  type: mc
  options:
  - A) Sorts the data
  - B) Preserves class distribution in train/test splits
  - C) Normalizes features
  - D) Removes outliers
  correct: B
  explanation: Maintains class distribution proportions in both train and test sets.
  chapter: Imbalanced data handling
- id: 181
  question: How do you import KFold?
  type: mc
  options:
  - A) from sklearn import KFold
  - B) from sklearn.model_selection import KFold
  - C) from sklearn.cross_validation import KFold
  - D) import sklearn.KFold
  correct: B
  explanation: Import KFold from sklearn.model_selection for cross-validation.
  chapter: Chapter 7
- id: 182
  question: What parameters does KFold require?
  type: mc
  options:
  - A) data, labels
  - B) n_splits, shuffle, random_state
  - C) X, y, splits
  - D) folds only
  correct: B
  explanation: n_splits defines folds; shuffle randomizes; random_state ensures reproducibility.
  chapter: Cross-validation
- id: 183
  question: What does n_splits parameter control?
  type: mc
  options:
  - A) Number of features
  - B) Number of folds in cross-validation
  - C) Train/test ratio
  - D) Number of models
  correct: B
  explanation: n_splits determines how many folds to split data into.
  chapter: CV configuration
- id: 184
  question: What does shuffle=True do in KFold?
  type: mc
  options:
  - A) Sorts data
  - B) Randomly shuffles data before splitting into folds
  - C) Removes randomness
  - D) Stratifies classes
  correct: B
  explanation: Randomly shuffles data before splitting into folds for better generalization.
  chapter: CV configuration
- id: 185
  question: Why use cross-validation?
  type: mc
  options:
  - A) Faster training
  - B) More robust performance estimates, uses all data for train/test
  - C) Increases accuracy
  - D) Reduces dataset size
  correct: B
  explanation: Uses all data for both training and testing, more robust than single
    split.
  chapter: Model evaluation
- id: 186
  question: How do you import GridSearchCV?
  type: mc
  options:
  - A) from sklearn import GridSearchCV
  - B) from sklearn.model_selection import GridSearchCV
  - C) from sklearn.grid_search import GridSearchCV
  - D) import sklearn.GridSearchCV
  correct: B
  explanation: Import GridSearchCV from sklearn.model_selection for hyperparameter
    tuning.
  chapter: Chapter 7
- id: 187
  question: What is the param_grid parameter?
  type: mc
  options:
  - A) Grid of data points
  - B) Dictionary of hyperparameters to search
  - C) Feature grid
  - D) Cross-validation folds
  correct: B
  explanation: Dictionary mapping parameter names to lists of values to try.
  chapter: Hyperparameter tuning
- id: 188
  question: How do you specify parameter names for pipeline steps?
  type: mc
  options:
  - A) stepname.param
  - B) stepname__param (double underscore)
  - C) stepname_param
  - D) stepname:param
  correct: B
  explanation: 'Use double underscore: ''stepname__param'' to access nested pipeline
    parameters.'
  chapter: Pipeline tuning
- id: 189
  question: What does the scoring parameter do?
  type: mc
  options:
  - A) Scores the data
  - B) Specifies metric to optimize (e.g., 'accuracy', 'recall')
  - C) Normalizes scores
  - D) Counts correct predictions
  correct: B
  explanation: Specifies which metric to optimize during hyperparameter search.
  chapter: Metric selection
- id: 190
  question: How do you access best parameters after fitting?
  type: mc
  options:
  - A) grid.parameters
  - B) grid.best_params_
  - C) grid.get_best_params()
  - D) grid.params
  correct: B
  explanation: Access best_params_ attribute to get optimal hyperparameter values.
  chapter: Result retrieval
- id: 191
  question: How do you access the best estimator?
  type: mc
  options:
  - A) grid.model
  - B) grid.best_estimator_
  - C) grid.get_estimator()
  - D) grid.estimator
  correct: B
  explanation: Access best_estimator_ attribute to get model fitted with best parameters.
  chapter: Model retrieval
- id: 192
  question: What does fit() do on GridSearchCV object?
  type: mc
  options:
  - A) Only fits one model
  - B) Fits all parameter combinations with CV, selects best
  - C) Validates parameters
  - D) Transforms data
  correct: B
  explanation: Tries all parameter combinations using cross-validation, stores best
    model.
  chapter: Model training
- id: 193
  question: What is n_jobs parameter?
  type: mc
  options:
  - A) Number of models
  - B) Number of parallel jobs/CPU cores to use
  - C) Number of iterations
  - D) Job priority
  correct: B
  explanation: Number of parallel jobs; -1 uses all CPU cores.
  chapter: Parallel processing
- id: 194
  question: What does n_jobs=-1 mean?
  type: mc
  options:
  - A) No parallelization
  - B) Use all available CPU cores
  - C) Use 1 core
  - D) Invalid value
  correct: B
  explanation: Uses all available CPU cores for parallel cross-validation.
  chapter: Resource utilization
- id: 195
  question: How do you specify custom scoring function?
  type: mc
  options:
  - A) scoring=my_function
  - B) scoring=make_scorer(my_function)
  - C) scoring='custom'
  - D) custom_scoring=my_function
  correct: B
  explanation: make_scorer() wraps scoring function for use in GridSearchCV.
  chapter: Chapter 8
- id: 196
  question: How do you import confusion_matrix?
  type: mc
  options:
  - A) from sklearn import confusion_matrix
  - B) from sklearn.metrics import confusion_matrix
  - C) from sklearn.evaluation import confusion_matrix
  - D) import sklearn.confusion_matrix
  correct: B
  explanation: Import confusion_matrix from sklearn.metrics for evaluation.
  chapter: Chapter 6
- id: 197
  question: What are the arguments to confusion_matrix()?
  type: mc
  options:
  - A) predictions, actual
  - B) y_true, y_pred
  - C) actual, predicted
  - D) y_pred, y_true
  correct: B
  explanation: 'First argument: true labels; second argument: predicted labels.'
  chapter: Evaluation
- id: 198
  question: What is the shape of a binary confusion matrix?
  type: mc
  options:
  - A) (1, 2)
  - B) (2, 2)
  - C) (2, 1)
  - D) (4, 4)
  correct: B
  explanation: '2x2 matrix for binary classification: rows actual, columns predicted.'
  chapter: Chapter 6
- id: 199
  question: What is the shape of a 3-class confusion matrix?
  type: mc
  options:
  - A) (2, 2)
  - B) (3, 3)
  - C) (3, 2)
  - D) (9, 9)
  correct: B
  explanation: '3x3 matrix for 3-class problem: K×K for K classes.'
  chapter: Multiclass evaluation
- id: 200
  question: How do you extract TP, TN, FP, FN from confusion matrix?
  type: mc
  options:
  - A) cm.get_values()
  - B) TN=cm[0,0], FP=cm[0,1], FN=cm[1,0], TP=cm[1,1]
  - C) cm.extract()
  - D) cm.values()
  correct: B
  explanation: Position [0,0]=TN, [0,1]=FP, [1,0]=FN, [1,1]=TP for binary.
  chapter: Manual metric calculation
- id: 201
  question: How do you import classification_report?
  type: mc
  options:
  - A) from sklearn import classification_report
  - B) from sklearn.metrics import classification_report
  - C) from sklearn.evaluation import classification_report
  - D) import sklearn.classification_report
  correct: B
  explanation: Import classification_report from sklearn.metrics for detailed metrics.
  chapter: Chapter 6
- id: 202
  question: What metrics does classification_report show?
  type: mc
  options:
  - A) Only accuracy
  - B) Precision, recall, f1-score, support per class
  - C) Only confusion matrix
  - D) Only AUC
  correct: B
  explanation: Shows precision, recall, f1-score, and support for each class.
  chapter: Comprehensive evaluation
- id: 203
  question: How should you display classification_report output?
  type: mc
  options:
  - A) Just call it
  - B) print(classification_report(y_true, y_pred))
  - C) classification_report.show()
  - D) display(classification_report())
  correct: B
  explanation: Use print() to display formatted text report.
  chapter: Output formatting (with print)
- id: 204
  question: What is support in classification report?
  type: mc
  options:
  - A) Model confidence
  - B) Number of actual occurrences of each class
  - C) Prediction accuracy
  - D) Feature importance
  correct: B
  explanation: Support is the number of actual samples for each class.
  chapter: Metric interpretation
- id: 205
  question: What is macro avg vs weighted avg?
  type: mc
  options:
  - A) They are the same
  - 'B) Macro: unweighted mean; Weighted: weighted by support'
  - C) Macro is better
  - D) Weighted ignores some classes
  correct: B
  explanation: 'Macro: simple average; weighted: average weighted by class sample
    counts.'
  chapter: Multiclass metrics
- id: 206
  question: How do you import accuracy_score?
  type: mc
  options:
  - A) from sklearn import accuracy_score
  - B) from sklearn.metrics import accuracy_score
  - C) from sklearn.scores import accuracy_score
  - D) import sklearn.accuracy
  correct: B
  explanation: Import accuracy_score from sklearn.metrics for accuracy calculation.
  chapter: Basic metrics
- id: 207
  question: How do you import precision_score?
  type: mc
  options:
  - A) from sklearn import precision_score
  - B) from sklearn.metrics import precision_score
  - C) from sklearn.scores import precision_score
  - D) import sklearn.precision
  correct: B
  explanation: Import precision_score from sklearn.metrics for precision calculation.
  chapter: Precision calculation
- id: 208
  question: How do you import recall_score?
  type: mc
  options:
  - A) from sklearn import recall_score
  - B) from sklearn.metrics import recall_score
  - C) from sklearn.scores import recall_score
  - D) import sklearn.recall
  correct: B
  explanation: Import recall_score from sklearn.metrics for recall calculation.
  chapter: Recall calculation
- id: 209
  question: How do you import f1_score?
  type: mc
  options:
  - A) from sklearn import f1_score
  - B) from sklearn.metrics import f1_score
  - C) from sklearn.scores import f1_score
  - D) import sklearn.f1
  correct: B
  explanation: Import f1_score from sklearn.metrics for F1-score calculation.
  chapter: F1 calculation
- id: 210
  question: What is the pos_label parameter?
  type: mc
  options:
  - A) Position of label
  - B) Specifies which class is 'positive' in binary classification
  - C) Label value
  - D) Positive score
  correct: B
  explanation: Specifies which class is positive in binary classification metrics.
  chapter: Binary classification
- id: 211
  question: How do you import make_scorer?
  type: mc
  options:
  - A) from sklearn import make_scorer
  - B) from sklearn.metrics import make_scorer
  - C) from sklearn.scoring import make_scorer
  - D) import sklearn.make_scorer
  correct: B
  explanation: Import make_scorer from sklearn.metrics to create custom scorers.
  chapter: Chapter 7
- id: 212
  question: How do you create a custom recall scorer?
  type: mc
  options:
  - A) scorer = recall_score
  - B) scorer = make_scorer(recall_score, pos_label='yes')
  - C) scorer = custom_scorer(recall)
  - D) scorer = create_scorer('recall')
  correct: B
  explanation: Wrap recall_score with make_scorer, specify pos_label for binary classification.
  chapter: Custom metrics
- id: 213
  question: What parameters does make_scorer accept?
  type: mc
  options:
  - A) Only the scoring function
  - B) score_func, greater_is_better, needs_proba, **kwargs
  - C) function, name
  - D) metric, data
  correct: B
  explanation: Takes scoring function, greater_is_better flag, and additional function
    parameters.
  chapter: Scorer configuration
- id: 214
  question: Why use make_scorer with GridSearchCV?
  type: mc
  options:
  - A) Required for GridSearchCV
  - B) To use custom metrics or specify metric parameters
  - C) To improve accuracy
  - D) To speed up search
  correct: B
  explanation: Enables custom metrics and metric parameters in hyperparameter search.
  chapter: Custom optimization
- id: 215
  question: How do you specify pos_label in make_scorer?
  type: mc
  options:
  - A) make_scorer(func, positive='yes')
  - B) make_scorer(func, pos_label='yes')
  - C) make_scorer(func, label='yes')
  - D) make_scorer(func).set_label('yes')
  correct: B
  explanation: Pass pos_label as keyword argument to make_scorer.
  chapter: Binary classification
- id: 216
  question: How do you import StandardScaler?
  type: mc
  options:
  - A) from sklearn import StandardScaler
  - B) from sklearn.preprocessing import StandardScaler
  - C) from sklearn.scaler import StandardScaler
  - D) import sklearn.StandardScaler
  correct: B
  explanation: Import StandardScaler from sklearn.preprocessing for feature scaling.
  chapter: Chapter 9
- id: 217
  question: What does StandardScaler do?
  type: mc
  options:
  - A) Scales to [0,1]
  - 'B) Standardizes features: mean=0, std=1'
  - C) Normalizes to unit length
  - D) Removes outliers
  correct: B
  explanation: 'Subtracts mean and divides by standard deviation: z-score normalization.'
  chapter: Feature scaling
- id: 218
  question: How do you fit and transform data?
  type: mc
  options:
  - A) scaler.transform(X_train)
  - B) scaler.fit(X_train); X_train_scaled = scaler.transform(X_train)
  - C) scaler.scale(X_train)
  - D) scaler(X_train)
  correct: B
  explanation: fit() learns parameters from training data; transform() applies transformation.
  chapter: Preprocessing workflow
- id: 219
  question: What is the difference between fit(), transform(), and fit_transform()?
  type: mc
  options:
  - A) No difference
  - 'B) fit: learns parameters; transform: applies; fit_transform: both'
  - C) All do the same thing
  - D) fit_transform is deprecated
  correct: B
  explanation: fit learns mean/std; transform applies; fit_transform does both together.
  chapter: Scaler usage
- id: 220
  question: Should you fit scaler on test data?
  type: mc
  options:
  - A) Yes, fit separately on test
  - B) No, only fit on training, transform test
  - C) Fit on both together
  - D) Doesn't matter
  correct: B
  explanation: No, fit only on training to prevent data leakage from test set.
  chapter: Data leakage prevention
- id: 221
  question: How do you import make_pipeline?
  type: mc
  options:
  - A) from sklearn import make_pipeline
  - B) from sklearn.pipeline import make_pipeline
  - C) from sklearn.preprocessing import make_pipeline
  - D) import sklearn.make_pipeline
  correct: B
  explanation: Import make_pipeline from sklearn.pipeline to chain transformers and
    estimators.
  chapter: Chapter 9
- id: 222
  question: What is a pipeline?
  type: mc
  options:
  - A) A data structure
  - B) Chains preprocessing and model steps sequentially
  - C) A plotting tool
  - D) A data loader
  correct: B
  explanation: Chains preprocessing and model steps ensuring consistent transformations.
  chapter: Workflow organization
- id: 223
  question: How do you create a pipeline with scaler and model?
  type: mc
  options:
  - A) pipeline([scaler, model])
  - B) make_pipeline(StandardScaler(), LogisticRegression())
  - C) Pipeline(scaler, model)
  - D) create_pipeline(scaler, model)
  correct: B
  explanation: 'Pass steps in order: make_pipeline(StandardScaler(), LogisticRegression()).'
  chapter: Standard workflow
- id: 224
  question: How do you access steps in a pipeline?
  type: mc
  options:
  - A) pipeline.get_steps()
  - B) pipeline.steps or pipeline.named_steps
  - C) pipeline[0]
  - D) pipeline.get(0)
  correct: B
  explanation: Use .steps attribute or .named_steps dictionary to access pipeline
    components.
  chapter: Pipeline inspection
- id: 225
  question: What is named_steps?
  type: mc
  options:
  - A) Step names only
  - B) Dictionary to access pipeline steps by name
  - C) Numbered steps
  - D) Step parameters
  correct: B
  explanation: Dictionary mapping step names to transformer/estimator objects.
  chapter: Step access
- id: 226
  question: How do you create dummy variables in pandas?
  type: mc
  options:
  - A) df.dummies()
  - B) pd.get_dummies(df)
  - C) df.create_dummies()
  - D) pd.dummy(df)
  correct: B
  explanation: pd.get_dummies() creates binary dummy variables for categorical features.
  chapter: All preprocessing
- id: 227
  question: What does drop_first=True prevent?
  type: mc
  options:
  - A) Data loss
  - B) Multicollinearity (dummy variable trap)
  - C) Missing values
  - D) Overfitting
  correct: B
  explanation: Prevents multicollinearity by avoiding dummy variable trap.
  chapter: Multicollinearity
- id: 228
  question: How do you handle multiple categorical columns?
  type: mc
  options:
  - A) One at a time only
  - B) pd.get_dummies(df, columns=['col1', 'col2'])
  - C) Cannot handle multiple
  - D) Use separate function
  correct: B
  explanation: Specify all categorical columns in columns parameter as list.
  chapter: Multi-column encoding
- id: 229
  question: What is the columns parameter in get_dummies()?
  type: mc
  options:
  - A) Columns to keep
  - B) Specific columns to encode
  - C) Output column names
  - D) Columns to drop
  correct: B
  explanation: List of categorical column names to encode; others remain unchanged.
  chapter: Selective encoding
- id: 230
  question: How do you drop specific columns after get_dummies?
  type: mc
  options:
  - A) df.remove(columns)
  - B) df.drop(columns=['col'], axis=1)
  - C) df.delete(['col'])
  - D) df.drop_columns(['col'])
  correct: B
  explanation: Use drop() with axis=1 or columns parameter to remove unwanted columns.
  chapter: Feature selection
- id: 231
  question: How do you import LogisticRegression?
  type: mc
  options:
  - A) from sklearn import LogisticRegression
  - B) from sklearn.linear_model import LogisticRegression
  - C) from sklearn.models import LogisticRegression
  - D) import sklearn.LogisticRegression
  correct: B
  explanation: Import LogisticRegression from sklearn.linear_model for classification.
  chapter: All LR chapters
- id: 232
  question: What is the C parameter?
  type: mc
  options:
  - A) Number of classes
  - B) Inverse of regularization strength
  - C) Convergence criterion
  - D) Class weight
  correct: B
  explanation: C is inverse of regularization strength; smaller C means more regularization.
  chapter: Chapter 7
- id: 233
  question: What is the class_weight parameter?
  type: mc
  options:
  - A) Weight of classifier
  - B) Weights for classes (e.g., 'balanced')
  - C) Feature weights
  - D) Sample weights
  correct: B
  explanation: Sets weights for classes to handle imbalanced datasets.
  chapter: Chapter 8
- id: 234
  question: What does multi_class='multinomial' do?
  type: mc
  options:
  - A) Handles binary only
  - B) Uses multinomial loss for multiclass
  - C) Creates multiple models
  - D) Not a valid parameter
  correct: B
  explanation: Uses multinomial loss with softmax for true multiclass classification.
  chapter: Chapter 14
- id: 235
  question: How do you access coefficients after fitting?
  type: mc
  options:
  - A) model.weights
  - B) model.coef_
  - C) model.coefficients
  - D) model.get_coef()
  correct: B
  explanation: Access coef_ attribute after fitting for coefficient values.
  chapter: Chapter 5
- id: 236
  question: How do you access intercept after fitting?
  type: mc
  options:
  - A) model.bias
  - B) model.intercept_
  - C) model.get_intercept()
  - D) model.beta0
  correct: B
  explanation: Access intercept_ attribute after fitting for intercept value.
  chapter: Chapter 5
- id: 237
  question: What does predict() return?
  type: mc
  options:
  - A) Probabilities
  - B) Predicted class labels
  - C) Confidence scores
  - D) Feature importances
  correct: B
  explanation: Returns predicted class labels as array.
  chapter: Predictions
- id: 238
  question: What does predict_proba() return?
  type: mc
  options:
  - A) Class labels
  - B) Probability estimates for each class
  - C) Binary predictions
  - D) Confidence intervals
  correct: B
  explanation: Returns probability estimates for each class as 2D array.
  chapter: Probability predictions
- id: 239
  question: What does the solver parameter control?
  type: mc
  options:
  - A) Data preprocessing
  - B) Optimization algorithm to use
  - C) Number of iterations
  - D) Learning rate
  correct: B
  explanation: Specifies optimization algorithm like lbfgs, liblinear, newton-cg,
    or sag.
  chapter: Optimization algorithm
- id: 240
  question: What is the default solver?
  type: mc
  options:
  - A) 'newton-cg'
  - B) 'lbfgs'
  - C) 'sag'
  - D) 'sgd'
  correct: B
  explanation: Default solver is lbfgs, effective for most problems.
  chapter: Default configuration
- id: 241
  question: How do you import DecisionTreeClassifier?
  type: mc
  options:
  - A) from sklearn import DecisionTreeClassifier
  - B) from sklearn.tree import DecisionTreeClassifier
  - C) from sklearn.models import DecisionTreeClassifier
  - D) import sklearn.DecisionTreeClassifier
  correct: B
  explanation: Import DecisionTreeClassifier from sklearn.tree for decision tree models.
  chapter: Chapter 16
- id: 242
  question: What is the criterion parameter?
  type: mc
  options:
  - A) Stopping criterion
  - B) Function to measure split quality (gini or entropy)
  - C) Pruning method
  - D) Tree depth
  correct: B
  explanation: 'Specifies function to measure split quality: gini or entropy.'
  chapter: Split criterion
- id: 243
  question: What are valid criterion values?
  type: mc
  options:
  - A) 'mse', 'mae'
  - B) 'gini', 'entropy'
  - C) 'accuracy', 'precision'
  - D) 'min', 'max'
  correct: B
  explanation: 'Valid values: ''gini'' for Gini impurity, ''entropy'' for information
    gain.'
  chapter: Gini vs Entropy
- id: 244
  question: What is max_depth?
  type: mc
  options:
  - A) Maximum features
  - B) Maximum tree depth
  - C) Maximum samples
  - D) Maximum nodes
  correct: B
  explanation: Limits maximum depth of tree to prevent overfitting.
  chapter: Chapter 17
- id: 245
  question: What is min_samples_split?
  type: mc
  options:
  - A) Minimum in leaf
  - B) Minimum samples to split a node
  - C) Minimum depth
  - D) Minimum features
  correct: B
  explanation: Minimum samples required in node to allow splitting.
  chapter: Pre-pruning
- id: 246
  question: What is min_samples_leaf?
  type: mc
  options:
  - A) Minimum to split
  - B) Minimum samples in a leaf node
  - C) Minimum depth
  - D) Minimum trees
  correct: B
  explanation: Minimum samples that must be present in leaf nodes.
  chapter: Pre-pruning
- id: 247
  question: What is min_impurity_decrease?
  type: mc
  options:
  - A) Maximum impurity
  - B) Minimum decrease in impurity to split
  - C) Impurity function
  - D) Leaf impurity
  correct: B
  explanation: Split only if it decreases impurity by this minimum amount.
  chapter: Pre-pruning
- id: 248
  question: What is ccp_alpha?
  type: mc
  options:
  - A) Learning rate
  - B) Complexity parameter for pruning
  - C) Split criterion
  - D) Feature importance threshold
  correct: B
  explanation: Complexity parameter for cost-complexity pruning; higher values mean
    more pruning.
  chapter: Post-pruning
- id: 249
  question: How do you access feature_importances_?
  type: mc
  options:
  - A) model.importances
  - B) model.feature_importances_
  - C) model.get_importances()
  - D) model.importance
  correct: B
  explanation: Access feature_importances_ attribute after fitting tree.
  chapter: Feature importance
- id: 250
  question: What does cost_complexity_pruning_path() return?
  type: mc
  options:
  - A) Pruned tree
  - B) Alpha values and corresponding impurities
  - C) Best alpha
  - D) Pruning decisions
  correct: B
  explanation: Returns alphas and corresponding impurities for choosing ccp_alpha.
  chapter: CCP implementation
